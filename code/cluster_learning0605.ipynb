{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 0, cost: 598.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 0, cost: 598.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 0, cost: 598.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 0, cost: 598.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 0, cost: 598.0\n",
      "Best run was number 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 0, cost: 594.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 0, cost: 594.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 0, cost: 594.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 0, cost: 594.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 0, cost: 594.0\n",
      "Best run was number 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 0, cost: 590.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 0, cost: 590.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 0, cost: 590.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 0, cost: 590.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 0, cost: 590.0\n",
      "Best run was number 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 0, cost: 580.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 0, cost: 580.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 0, cost: 580.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 0, cost: 580.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 0, cost: 580.0\n",
      "Best run was number 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 0, cost: 570.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 0, cost: 570.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 0, cost: 570.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 0, cost: 570.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 0, cost: 570.0\n",
      "Best run was number 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 0, cost: 560.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 0, cost: 560.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 0, cost: 560.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 0, cost: 560.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 0, cost: 560.0\n",
      "Best run was number 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 0, cost: 550.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 0, cost: 550.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 0, cost: 550.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 0, cost: 550.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 0, cost: 550.0\n",
      "Best run was number 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 1, iteration: 1/100, moves: 0, cost: 540.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 2, iteration: 1/100, moves: 0, cost: 540.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 3, iteration: 1/100, moves: 0, cost: 540.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 4, iteration: 1/100, moves: 0, cost: 540.0\n",
      "Init: initializing centroids\n",
      "Init: initializing clusters\n",
      "Starting iterations...\n",
      "Run 5, iteration: 1/100, moves: 0, cost: 540.0\n",
      "Best run was number 1\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering, OPTICS, MeanShift ,SpectralClustering\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import adjusted_rand_score, silhouette_score\n",
    "from kmodes.kmodes import KModes\n",
    "import hdbscan\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "# pip install kmodes\n",
    "# pip install quickshift-tsne from quickshift import quickshift\n",
    "# pip install hdbscan import hdbscan\n",
    "# 读取数据\n",
    "file_path = r'E:/FedStream/data_set_syn/Synthetic0310/2Dim_9A1B/forCluster/round_0.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 只取类1的数据\n",
    "# k-means\n",
    "# class_1_data = data[data.iloc[:, -1] == 0]\n",
    "class_1_data = data[data.iloc[:, -1] == 1]\n",
    "\n",
    "# 提取特征\n",
    "X = class_1_data.iloc[:, 0:2].values\n",
    "\n",
    "# 圆的中心和半径\n",
    "circle_centers = [(0, 0), (0.25, 0.75), (0.75, 0.25), (-0.25, 0.75), (-0.75, 0.25), (-0.25, -0.75), (-0.75, -0.25), (0.25, -0.75), (0.75, -0.25)]\n",
    "radii = [0.45] + [0.23] * 8\n",
    "\n",
    "# 可视化原始数据和聚类原型\n",
    "def plot_clusters_with_centroids_and_circles(X, labels, centroids, circle_centers, radii, title,save_path):\n",
    "    fig, ax = plt.subplots()\n",
    "    # fig.set_size_inches(3.35 / 2.54, 3.5 / 2.54)  # 将尺寸转换为英寸\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', marker='o', label='Data points')\n",
    "    ax.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', s=50, label='Centroids')\n",
    "\n",
    "    for center, radius in zip(circle_centers, radii):\n",
    "        circle = Circle(center, radius, color='blue', fill=False, linewidth=2, linestyle='--')\n",
    "        ax.add_patch(circle)\n",
    "\n",
    "    ax.set_aspect('equal', 'box')  # 确保坐标轴比例相同\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Feature 1')\n",
    "    ax.set_ylabel('Feature 2')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plotK_Means(cluters_nums):\n",
    "    # 选择并应用聚类算法（选择K-means为例）\n",
    "    kmeans = KMeans(n_clusters=cluters_nums, random_state=0).fit(X)\n",
    "    labels_kmeans = kmeans.labels_\n",
    "    centroids_kmeans = kmeans.cluster_centers_\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/k_means/{cluters_nums}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_kmeans, centroids_kmeans, circle_centers, radii, f'K-means , cluster nums : {cluters_nums}',save_path=save_path)\n",
    "\n",
    "def plotDBSCAN(eps, min_samples):\n",
    "    dbscan = DBSCAN(eps=eps, min_samples=min_samples).fit(X)\n",
    "    labels_dbscan = dbscan.labels_\n",
    "    centroids_dbscan = np.array([X[labels_dbscan == i].mean(axis=0) for i in range(len(set(labels_dbscan)) - (1 if -1 in labels_dbscan else 0))])\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/DBSCAN/eps_{eps}_min_samples_{min_samples}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_dbscan, centroids_dbscan, circle_centers, radii, f'DBSCAN, eps: {eps}, min_samples: {min_samples}', save_path)\n",
    "def plotHDBSCAN(min_cluster_size):\n",
    "    hdb = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size).fit(X)\n",
    "    labels_hdbscan = hdb.labels_\n",
    "    centroids_hdbscan = np.array([X[labels_hdbscan == i].mean(axis=0) for i in range(len(set(labels_hdbscan)) - (1 if -1 in labels_hdbscan else 0))])\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/HDBSCAN/min_cluster_size_{min_cluster_size}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_hdbscan, centroids_hdbscan, circle_centers, radii, f'HDBSCAN, min_cluster_size: {min_cluster_size}', save_path)\n",
    "\n",
    "def plotAgglomerative(cluters_nums):\n",
    "    agg = AgglomerativeClustering(n_clusters=cluters_nums).fit(X)\n",
    "    labels_agg = agg.labels_\n",
    "    # 由于Agglomerative Clustering没有中心点，需要计算每个簇的质心\n",
    "    centroids_agg = np.array([X[labels_agg == i].mean(axis=0) for i in range(len(set(labels_agg)))])\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/Agglomerative/{cluters_nums}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_agg, centroids_agg, circle_centers, radii, f'Agglomerative, cluster nums : {cluters_nums}',save_path=save_path)\n",
    "def plotKModes(clusters_num):\n",
    "    kmodes = KModes(n_clusters=clusters_num, init='Huang', n_init=5, verbose=1)\n",
    "    labels_kmodes = kmodes.fit_predict(X)\n",
    "    centroids_kmodes = kmodes.cluster_centroids_\n",
    "    print(type(labels_kmodes))\n",
    "    print(type(centroids_kmodes))\n",
    "    # save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/KModes/{clusters_num}.png'\n",
    "    # plot_clusters_with_centroids_and_circles(X, labels_kmodes, centroids_kmodes, circle_centers, radii, f'K-Modes, cluster nums: {clusters_num}', save_path)\n",
    "def quickshift_clustering(X, tau=0.1, k=10):\n",
    "    n_samples = X.shape[0]\n",
    "    nn = NearestNeighbors(n_neighbors=k+1).fit(X)\n",
    "    distances, indices = nn.kneighbors(X)\n",
    "\n",
    "    labels = -np.ones(n_samples)\n",
    "    labels[0] = 0  # Initialize first point as the first cluster\n",
    "    current_label = 0\n",
    "\n",
    "    for i in range(1, n_samples):\n",
    "        min_dist = np.inf\n",
    "        best_j = -1\n",
    "\n",
    "        # 遍历当前点i的所有近邻\n",
    "        for idx in range(1, k+1):  # 跳过自身（索引0是自己）\n",
    "            j = indices[i][idx]\n",
    "            dist_to_j = distances[i][idx]\n",
    "\n",
    "            # 检查距离是否是目前最小，且小于tau\n",
    "            if dist_to_j < min_dist and dist_to_j < tau:\n",
    "                min_dist = dist_to_j\n",
    "                best_j = j\n",
    "\n",
    "        # 根据最近的有效邻居（距离小于tau）设置簇标签\n",
    "        if best_j != -1 and labels[best_j] != -1:\n",
    "            labels[i] = labels[best_j]\n",
    "        else:\n",
    "            current_label += 1\n",
    "            labels[i] = current_label\n",
    "\n",
    "    return labels\n",
    "\n",
    "def plotQuickShift(tau,cluster_nums):\n",
    "    labels_quickshift = quickshift_clustering(X, tau=tau, k=cluster_nums)\n",
    "    centroids_quickshift = np.array([X[labels_quickshift == i].mean(axis=0) for i in range(len(set(labels_quickshift)) - (1 if -1 in labels_quickshift else 0))])\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/QuickShift/tau_{tau}_k_{cluster_nums}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_quickshift, centroids_quickshift, circle_centers, radii, f'QuickShift, tau: {tau},cluster:{cluster_nums}', save_path)\n",
    "\n",
    "def plotOPTICS(min_samples):\n",
    "    optics = OPTICS(min_samples=min_samples).fit(X)\n",
    "    labels_optics = optics.labels_\n",
    "    centroids_optics = np.array([X[labels_optics == i].mean(axis=0) for i in range(len(set(labels_optics)) - (1 if -1 in labels_optics else 0))])\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/OPTICS/min_samples_{min_samples}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_optics, centroids_optics, circle_centers, radii, f'OPTICS, min_samples: {min_samples}', save_path)\n",
    "\n",
    "def plotMeanShift(bandwidth):\n",
    "    mean_shift = MeanShift(bandwidth=bandwidth).fit(X)\n",
    "    labels_meanshift = mean_shift.labels_\n",
    "    centroids_meanshift = mean_shift.cluster_centers_\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/MeanShift/meanshift_bandwidth_{bandwidth}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_meanshift, centroids_meanshift, circle_centers, radii, f'Mean Shift (Bandwidth={bandwidth})', save_path)\n",
    "\n",
    "def plotGaussianMixture(clusters_num):\n",
    "    # 选择并应用高斯混合模型\n",
    "    gmm = GaussianMixture(n_components=clusters_num, random_state=0).fit(X)\n",
    "    labels_gmm = gmm.predict(X)\n",
    "    centroids_gmm = gmm.means_  # 高斯混合模型的质心是每个成分的均值\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/GaussianMixture/{clusters_num}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_gmm, centroids_gmm, circle_centers, radii, f'Gaussian Mixture, cluster nums: {clusters_num}', save_path)\n",
    "\n",
    "def plotSpectralClustering(clusters_num):\n",
    "    spectral = SpectralClustering(n_clusters=clusters_num, random_state=0, affinity='nearest_neighbors').fit(X)\n",
    "    labels_spectral = spectral.labels_\n",
    "    # 由于 Spectral Clustering 没有质心，我们计算每个簇的质心\n",
    "    centroids_spectral = np.array([X[labels_spectral == i].mean(axis=0) for i in range(clusters_num)])\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/SpectralClustering/{clusters_num}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_spectral, centroids_spectral, circle_centers, radii, f'Spectral Clustering, cluster nums: {clusters_num}', save_path)\n",
    "\n",
    "\n",
    "def plotKMedoids(clusters_num):\n",
    "    kmedoids = KMedoids(n_clusters=clusters_num, random_state=0).fit(X)\n",
    "    labels_kmedoids = kmedoids.labels_\n",
    "    centroids_kmedoids = kmedoids.cluster_centers_\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/KMedoids/{clusters_num}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_kmedoids, centroids_kmedoids, circle_centers, radii, f'K-Medoids, cluster nums: {clusters_num}', save_path)\n",
    "\n",
    "def plotKMeansPlusPlus(clusters_num):\n",
    "    kmeans_plus_plus = KMeans(n_clusters=clusters_num, init='k-means++', random_state=0).fit(X)\n",
    "    labels_kmeans_plus_plus = kmeans_plus_plus.labels_\n",
    "    centroids_kmeans_plus_plus = kmeans_plus_plus.cluster_centers_\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/KMeansPlusPlus/{clusters_num}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_kmeans_plus_plus, centroids_kmeans_plus_plus, circle_centers, radii, f'K-Means++, cluster nums: {clusters_num}', save_path)\n",
    "\n",
    "# 示例 Density Peaks Clustering（DPC）\n",
    "# 注意：这里假设你已经有实现 DPC 算法的代码\n",
    "# from sklearn.metrics.pairwise import euclidean_distances\n",
    "def plotDensityPeaksClustering(clusters_num):\n",
    "    # 计算欧氏距离矩阵\n",
    "    distances = euclidean_distances(X, X)\n",
    "    # 计算每个点的局部密度\n",
    "    dc = np.percentile(distances, 2)  # 设置截断距离 dc\n",
    "    rho = np.sum(np.exp(-(distances / dc) ** 2), axis=1) - 1\n",
    "    # 计算每个点与比它密度更大的点的最小距离\n",
    "    delta = np.zeros_like(rho)\n",
    "    for i in range(len(rho)):\n",
    "        greater_density = np.where(rho > rho[i])[0]\n",
    "        if len(greater_density) > 0:\n",
    "            delta[i] = np.min(distances[i, greater_density])\n",
    "        else:\n",
    "            delta[i] = np.max(distances[i])\n",
    "    # # 确定簇中心\n",
    "    cluster_centers = np.argsort(-rho * delta)[:clusters_num]  # 假设clusters_num个簇\n",
    "    labels = np.zeros(len(X), dtype=int)\n",
    "    # 分配每个点到最近的簇中心\n",
    "    for i in range(len(X)):\n",
    "        if i in cluster_centers:\n",
    "            labels[i] = np.where(cluster_centers == i)[0][0]\n",
    "        else:\n",
    "            labels[i] = labels[np.argmin(distances[i, cluster_centers])]\n",
    "\n",
    "    labels_dpc = labels\n",
    "    centroids_dpc = X[cluster_centers]  # 使用索引获取簇中心的坐标\n",
    "    save_path = f'C:/Users/张腾森/Desktop/modelV/cluster/DensityPeaksClustering/{clusters_num}.png'\n",
    "    plot_clusters_with_centroids_and_circles(X, labels_dpc, centroids_dpc, circle_centers, radii, f'Density Peaks Clustering, cluster nums: {clusters_num}', save_path)\n",
    "# k-means,Agglomerative\n",
    "cluster_list = [1,3,5,10,15,20,25,30]\n",
    "# 如需使用其他算法，请解注释以下部分并注释掉相应的K-means部分\n",
    "for cluster_nums in cluster_list:\n",
    "    # plotK_Means(cluters_nums=cluster_nums)\n",
    "    # plotAgglomerative(cluters_nums=cluster_nums)\n",
    "    # plotKMedoids(clusters_num=cluster_nums)\n",
    "    # plotKMeansPlusPlus(clusters_num=cluster_nums)\n",
    "    # plotDensityPeaksClustering(clusters_num=cluster_nums)\n",
    "    # plotGaussianMixture(clusters_num =cluster_nums )\n",
    "    # plotSpectralClustering(clusters_num =cluster_nums)\n",
    "    plotKModes(clusters_num =cluster_nums)\n",
    "\n",
    "# 示例 DBSCAN 参数组合\n",
    "# 定于域[-1,1],[-1,1]\n",
    "# eps_list = [0.1, 0.15, 0.2, 0.3]\n",
    "# min_samples_list = [2, 3, 5, 10, 15, 20, 25]\n",
    "# for min_samples in min_samples_list:\n",
    "#     for eps in eps_list:\n",
    "#         # plotDBSCAN(eps=eps, min_samples=min_samples)\n",
    "#         pass  # Since DBSCAN is commented out, this will not execute\n",
    "#     plotOPTICS(min_samples=min_samples)\n",
    "#     plotHDBSCAN(min_cluster_size=min_samples)\n",
    "# bandwidth_list = [0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5,0.6]\n",
    "# for bandwidth in bandwidth_list:\n",
    "#     plotMeanShift(bandwidth)\n",
    "# tau_list =[0.1,0.5,1,2]\n",
    "# clusterL = [3]\n",
    "# for tau in tau_list:\n",
    "#     for c in clusterL:\n",
    "#         plotQuickShift(tau=tau,cluster_nums=c)\n",
    "# 1. K-means 聚类 kmeans = KMeans(n_clusters=3, random_state=0).fit(X)\n",
    "# 2. 层次聚类 (Hierarchical Clustering),hierarchical = AgglomerativeClustering(n_clusters=3).fit(X)\n",
    "# 3. DBSCAN (Density-Based Spatial Clustering of Applications with Noise),dbscan = DBSCAN(eps=0.1, min_samples=5).fit(X\n",
    "# 4. Mean Shift 聚类 from sklearn.cluster import MeanShift,# Mean Shift 聚类,meanshift = MeanShift().fit(X),labels = meanshift.labels_,centers = meanshift.cluster_centers_\n",
    "# 5. 高斯混合模型 (Gaussian Mixture Model, GMM),from sklearn.mixture import GaussianMixture,gmm = GaussianMixture(n_components=3, random_state=0).fit(X),labels = gmm.predict(X)\n",
    "# 6. 评估自组织映射 (Self-Organizing Map, SOM),from minisom import MiniSom,som = MiniSom(x=10, y=10, input_len=3, sigma=0.3, learning_rate=0.5),som.random_weights_init(X),som.train_random(X, 100),labels = np.array([som.winner(x) for x in X])\n",
    "# 7. Spectral Clustering,from sklearn.cluster import SpectralClustering,spectral = SpectralClustering(n_clusters=3, affinity='nearest_neighbors').fit(X),labels = spectral.labels_\n",
    "# 8. 期望最大化聚类 (Expectation-Maximization Clustering),from sklearn.mixture import GaussianMixture,em = GaussianMixture(n_components=3, random_state=0).fit(X)labels = em.predict(X)\n",
    "\n",
    "# 基于密度的\n",
    "# 1. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)，通过识别密度高的区域来形成簇。\n",
    "# 2. OPTICS (Ordering Points To Identify the Clustering Structure)，与DBSCAN类似，但能够识别不同密度的簇。\n",
    "    # from sklearn.cluster import OPTICS，optics = OPTICS(min_samples=5).fit(X)，labels = optics.labels_\n",
    "# 3. HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise),是DBSCAN的改进版本，能够自动确定簇的数量，并且更好地处理不同密度的簇。\n",
    "    # pip install hdbscan，import hdbscan，hdb = hdbscan.HDBSCAN(min_cluster_size=5).fit(X)，labels = hdb.labels_\n",
    "# 4. Quickshift 通过找到数据点之间的密度峰值来形成簇。\n",
    "    # pip install quickshift-tsne,from quickshift import quickshift,bandwidth = 0.1  # 设定带宽参数,cluster_ids = quickshift(X, kernel='gaussian', bandwidth=bandwidth)\n",
    "\n",
    "# 基于峰值\n",
    "# 1.Mean Shift,通过将数据点向密度最大的位置（均值）移动来形成簇。\n",
    "# 2.K-medoids 聚类 (Partitioning Around Medoids PAM) 通过选择实际数据点作为簇中心来进行聚类。它对于处理噪声和异常值更加鲁棒。\n",
    "    # pip install scikit-learn scikit-learn-extra,from sklearn_extra.cluster import KMedoids,kmedoids = KMedoids(n_clusters=3, random_state=0).fit(X).,labels = kmedoids.labels_,medoids = kmedoids.cluster_centers_\n",
    "# 3 K-modes, K-means 的变体，专门用于处理分类数据（即离散数据）。与 K-means 使用均值作为质心不同，K-modes 使用众数作为质心。\n",
    "# 4. K-means++ ,主要解决了初始簇中心选择的问题，通过更智能的初始化方法提高了聚类效果。\n",
    "# 5. Density Peaks Clustering,首先计算每个点的局部密度，然后根据局部密度的峰值来形成簇。\n",
    "    # from sklearn.metrics.pairwise import euclidean_distances\n",
    "    #AgglomerativeDBSCANDensityPeaksClusteringGaussianMixturek_meansKMeansPlusPlusKMedoidsMeanShiftOPTICSSpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
